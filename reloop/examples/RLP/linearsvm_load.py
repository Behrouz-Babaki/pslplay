import psycopg2
import getpass
import logging
import sys

logging.basicConfig(stream=sys.stdout, level=logging.INFO)

log = logging.getLogger(__name__)

"""
For a given cora file this script populates a specified database with tables needed for running the LPSVM.
Therefore you have to provide your login credentials to the database as well as a name for the Database itself.
You will then be asked for the location of the cora file.

In this example the cora files are assumed to be located in the ../cora folder. If you would like to create a seperate
database then you will be prompted to provide the name for the new database.

The assumed format for the cora files is:

paper_id  vocabulary(binary vector)  label
34530     0 0 0 1 1 0 1 0 0 1 1 1 0  -1
...

Where each row is assumed to have the same length since the data is based on a shared vocabulary, where True(1) implies
the word a the position occurs in the abstract and False(0) implies that the word does not occur in the abstract with the
given paper_id

The labels were generated by combining the five least abundant labels to the -1 and the most common label to 1.

Computing the kernel can be achieved in two ways. We provide a pgpsql function for in database computation of the kernel.
Alternatively you can choose to precompute the kernel with numpy and populate the database before running reloop.
"""

db_name = raw_input(
    "Please specifiy the name of your Database (WARNING: this deletes the current contents of the database! Please use a dummy database.): ")
db_user = raw_input("Pease specify the Username for the Database: ")
db_password = getpass.getpass("Enter your password (Leave blank if None):")

connection = psycopg2.connect("dbname=" + db_name + " user=" + db_user + " password=" + db_password)
cursor = connection.cursor()

path = raw_input("Please specify a path for a cora data file: ")
file = open("../cora/reldata/" + path, "r")

if raw_input("Do you want to create a new database for the User " + db_user + " with the name " + path + "? (y/n)") == 'y':
    db_name = raw_input("Please specifiy your prefered name for the database: ")

    connection.set_isolation_level(0)
    cursor.execute(
        "CREATE DATABASE " + db_name + " WITH OWNER=" + db_user + " ENCODING = 'UTF8' TABLESPACE = pg_default LC_COLLATE = 'en_US.UTF-8' LC_CTYPE = 'en_US.UTF-8' CONNECTION LIMIT = -1;")
    connection.set_isolation_level(1)

connection.commit()
connection.close()

cora_connection = psycopg2.connect("dbname=" + db_name + " user=" + db_user + " password=" + db_password)
cora_cursor = cora_connection.cursor()

cora_cursor.execute("DROP TABLE IF EXISTS word_vector")
cora_cursor.execute("CREATE TABLE word_vector (id SERIAL PRIMARY KEY, paper_id int, word_id int)")

cora_cursor.execute("DROP TABLE IF EXISTS paper")
cora_cursor.execute("CREATE TABLE paper (id SERIAL PRIMARY KEY, paper_id int)")

cora_cursor.execute("DROP TABLE IF EXISTS label")
cora_cursor.execute("CREATE TABLE label (id SERIAL PRIMARY KEY, bin_label int)")

# Function used to compute the Kernel in Postgres if desired.
cora_cursor.execute("CREATE OR REPLACE FUNCTION rbf_kernel(_c1 int, _c2 int) \
                    RETURNS FLOAT AS\
                    $func$\
                    DECLARE result FLOAT;\
                    BEGIN\
                       EXECUTE format('WITH word_id_1 as (SELECT word_id FROM word_vector where paper_id=%s),\
                                            word_id_2 as (SELECT word_id FROM word_vector where paper_id=%s),\
                                            word_id_union as (SELECT count(*) as word_id_union_count FROM (SELECT * from word_id_1 UNION SELECT * from word_id_2)y),\
                                            word_id_intersection as (SELECT count(*) as word_id_intersection_count FROM (SELECT * from word_id_1 INTERSECT SELECT * from word_id_2)x)\
                                            SELECT exp(0.01*-1*(word_id_union.word_id_union_count - word_id_intersection.word_id_intersection_count)) AS counter_intersection FROM word_id_intersection, word_id_union', _c1, _c2) INTO result;\
                       RETURN result;\
                    END\
                    $func$ LANGUAGE plpgsql;")

bin_vectors = []
for index, line in enumerate(file):
    temp = line.split(",")
    paper_id = -1
    for ind, elem in enumerate(temp[:len(temp) - 1]):
        if ind == 0:
            paper_id = elem
        elif elem == '1':
            bin_vectors.append((paper_id, str(ind), 1))
        else:
            continue

    cora_cursor.execute("Insert into paper (paper_id) VALUES (" + str(temp[0]) + ");")
    cora_cursor.execute("Insert into label (bin_label) VALUES (" + str(temp[len(temp) - 1]) + ");")
    if index % 50 == 0:
        log.info(str(index) + " Papers scanned...")
log.info(str(index) + " Finished scanning papers from " + path + ".")

log.info("Inserting relations into database...")
query = "INSERT INTO word_vector (paper_id, word_id)VALUES" + ",".join(
    "(" + item[0] + "," + str(item[1]) + ")" for item in bin_vectors) + ";"

cora_cursor.execute(query)
cora_cursor.execute("CREATE INDEX word_idx ON word_vector USING btree (paper_id, word_id);")


log.info("Successfully populated " + db_name + " with necessary relations.")

file.close()

#Kernel Computation
if raw_input("Do you want to precompute the Kernel ?(y/n)") == 'y':
    import numpy as np
    import time
    file = open("../cora/reldata/" + path, "r")
    cora_cursor.execute("DROP TABLE IF EXISTS rbf_values;")
    cora_cursor.execute("CREATE TABLE rbf_values (paper1_id int , paper2_id int, rbf_value float );")
    log.info("Starting kernel computation...")

    def rbf_kernel(x, y, gamma=0.01):
        res = np.linalg.norm(x-y) ** 2
        res *= -1 * gamma
        return np.exp(res)

    bin_vectors = {}
    start = time.time()
    for index, line in enumerate(file):
        temp = line.split(",")
        paper_id = temp[0]
        bin_vector = np.array(np.int32(temp[1:len(temp)-1]))
        bin_vectors[paper_id] = bin_vector

    rbf_values = {}

    i = 0
    for paper_id, bin_vector in bin_vectors.iteritems():
        rbf_values[paper_id] = {}
        for paper_id2, bin_vector2 in bin_vectors.iteritems():
            rbf_values[paper_id][paper_id2] = rbf_kernel(bin_vector, bin_vector2)

    end = time.time()
    log.info("Time needed to compute the rbf kernel: " + str(end-start))

    values = []
    print ("Finished computing kernel values.")
    for p_id, k_values in rbf_values.iteritems():
        for paper_id, kernel_value in k_values.iteritems():
            values.append((p_id, paper_id, kernel_value))
        i += 1
        if i % 100 == 0:
            log.info(str(i) + " papers scanned.")


    cora_cursor.execute("INSERT INTO rbf_values VALUES " +  ",".join([ "(" + str(p_id) + ", " + str(paper_id) + ", " + str(kernel_value) + ")" for p_id, paper_id, kernel_value in values]) + ";")
    log.info("Successfully populated " + db_name + " with precomputed kernel values.")
    file.close()

cora_connection.commit()
cora_connection.close()